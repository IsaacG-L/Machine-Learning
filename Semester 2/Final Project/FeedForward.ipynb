{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74efe62",
   "metadata": {},
   "source": [
    "###### This is for the second model that we are using which is a feedforward neural network!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cae753",
   "metadata": {},
   "source": [
    "##### Here is a link just for you!:\n",
    "https://www.geeksforgeeks.org/feedforward-neural-network/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db4005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9992c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run PrepTime.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aab8ec60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\AppData\\Local\\Temp\\ipykernel_27332\\839577113.py:2: DtypeWarning: Columns (0,3,5,19,20,24,25,26,27,28,36,37,38,39,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"nutritional.tsv\", sep=\"\\t\")\n"
     ]
    }
   ],
   "source": [
    "df = maindf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a49c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = artificialCalories(df)\n",
    "df = RecoScore(df)\n",
    "df = shouldYou()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8956c817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are columns that have negative sugar!?!\n",
    "df = df.drop([8642, 119086, 152522, 165746])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc3477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3ab79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>energy_100g</th>\n",
       "      <th>fat_100g</th>\n",
       "      <th>saturated-fat_100g</th>\n",
       "      <th>trans-fat_100g</th>\n",
       "      <th>cholesterol_100g</th>\n",
       "      <th>carbohydrates_100g</th>\n",
       "      <th>sugars_100g</th>\n",
       "      <th>fiber_100g</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>expected_cal</th>\n",
       "      <th>score</th>\n",
       "      <th>encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Banana Chips Sweetened (Whole)</td>\n",
       "      <td>2243.0</td>\n",
       "      <td>28.57</td>\n",
       "      <td>28.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018</td>\n",
       "      <td>64.29</td>\n",
       "      <td>14.29</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>528.57</td>\n",
       "      <td>0.362669</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peanuts</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>17.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>60.71</td>\n",
       "      <td>17.86</td>\n",
       "      <td>7.1</td>\n",
       "      <td>17.86</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.071</td>\n",
       "      <td>475.02</td>\n",
       "      <td>0.315985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Granola Cranberry And Acai</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>10.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>74.55</td>\n",
       "      <td>25.45</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.036</td>\n",
       "      <td>432.75</td>\n",
       "      <td>0.338423</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Peanuts, Mixed Nuts</td>\n",
       "      <td>2389.0</td>\n",
       "      <td>42.86</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25.00</td>\n",
       "      <td>14.29</td>\n",
       "      <td>7.1</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.071</td>\n",
       "      <td>585.74</td>\n",
       "      <td>0.472592</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Cranberries</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>83.33</td>\n",
       "      <td>66.67</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>333.32</td>\n",
       "      <td>0.666700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       product_name  energy_100g  fat_100g  \\\n",
       "1    Banana Chips Sweetened (Whole)       2243.0     28.57   \n",
       "2                           Peanuts       1941.0     17.86   \n",
       "79       Granola Cranberry And Acai       1824.0     10.91   \n",
       "82              Peanuts, Mixed Nuts       2389.0     42.86   \n",
       "148                     Cranberries       1255.0      0.00   \n",
       "\n",
       "     saturated-fat_100g  trans-fat_100g  cholesterol_100g  carbohydrates_100g  \\\n",
       "1                 28.57             0.0             0.018               64.29   \n",
       "2                  0.00             0.0             0.000               60.71   \n",
       "79                 0.91             0.0             0.000               74.55   \n",
       "82                 7.14             0.0             0.000               25.00   \n",
       "148                0.00             0.0             0.000               83.33   \n",
       "\n",
       "     sugars_100g  fiber_100g  proteins_100g  sodium_100g  calcium_100g  \\\n",
       "1          14.29         3.6           3.57        0.000         0.000   \n",
       "2          17.86         7.1          17.86        0.250         0.071   \n",
       "79         25.45         5.5           9.09        0.100         0.036   \n",
       "82         14.29         7.1          25.00        0.214         0.071   \n",
       "148        66.67        10.0           0.00        0.000         0.000   \n",
       "\n",
       "     expected_cal     score  encode  \n",
       "1          528.57  0.362669       2  \n",
       "2          475.02  0.315985       1  \n",
       "79         432.75  0.338423       1  \n",
       "82         585.74  0.472592       2  \n",
       "148        333.32  0.666700       2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74065c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cda554a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as ts\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee416ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9636afcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "424cecde",
   "metadata": {},
   "source": [
    "The code below is just so that you can compare and contrast and have a general idea!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e695be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['fat_100g', 'sugars_100g']]\n",
    "y = df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2013a741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\igarcialopez\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 0.1437 - mae: 0.0744 - val_loss: 4.1195e-04 - val_mae: 0.0139\n",
      "Epoch 2/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.0033 - mae: 0.0263 - val_loss: 0.0016 - val_mae: 0.0223\n",
      "Epoch 3/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.0038 - mae: 0.0271 - val_loss: 3.2381e-05 - val_mae: 0.0036\n",
      "Epoch 4/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.2210e-04 - mae: 0.0054 - val_loss: 3.4886e-05 - val_mae: 0.0037\n",
      "Epoch 5/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3.8371e-04 - mae: 0.0058 - val_loss: 1.2575e-05 - val_mae: 0.0023\n",
      "Epoch 6/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.5979e-04 - mae: 0.0067 - val_loss: 2.8792e-04 - val_mae: 0.0112\n",
      "Epoch 7/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.0010 - mae: 0.0129 - val_loss: 3.9704e-04 - val_mae: 0.0136\n",
      "Epoch 8/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.0015 - mae: 0.0143 - val_loss: 9.6471e-06 - val_mae: 0.0021\n",
      "Epoch 9/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 5.2204e-04 - mae: 0.0089 - val_loss: 6.5835e-06 - val_mae: 0.0018\n",
      "Epoch 10/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.3663e-04 - mae: 0.0055 - val_loss: 1.7644e-04 - val_mae: 0.0071\n",
      "Epoch 11/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 4.0105e-04 - mae: 0.0079 - val_loss: 5.5516e-06 - val_mae: 0.0018\n",
      "Epoch 12/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.9447e-04 - mae: 0.0071 - val_loss: 4.4002e-05 - val_mae: 0.0043\n",
      "Epoch 13/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.7876e-04 - mae: 0.0049 - val_loss: 3.2469e-05 - val_mae: 0.0038\n",
      "Epoch 14/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.0449e-04 - mae: 0.0044 - val_loss: 0.0033 - val_mae: 0.0300\n",
      "Epoch 15/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.7266e-04 - mae: 0.0059 - val_loss: 9.7648e-05 - val_mae: 0.0067\n",
      "Epoch 16/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.2500e-04 - mae: 0.0044 - val_loss: 2.2844e-05 - val_mae: 0.0030\n",
      "Epoch 17/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.1137e-05 - mae: 0.0041 - val_loss: 1.8691e-06 - val_mae: 9.0411e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.2482e-05 - mae: 0.0014 - val_loss: 7.8368e-07 - val_mae: 6.6228e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 4.2049e-05 - mae: 0.0022 - val_loss: 1.5005e-06 - val_mae: 8.9700e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.0256e-05 - mae: 0.0015 - val_loss: 2.1823e-07 - val_mae: 3.6355e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 5.7454e-05 - mae: 0.0023 - val_loss: 5.7641e-06 - val_mae: 0.0016\n",
      "Epoch 22/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 8.5169e-06 - mae: 0.0011 - val_loss: 7.6208e-08 - val_mae: 1.8220e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3.2952e-06 - mae: 7.9906e-04 - val_loss: 3.8049e-06 - val_mae: 0.0014\n",
      "Epoch 24/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.9656e-06 - mae: 6.2395e-04 - val_loss: 7.8869e-08 - val_mae: 1.5359e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.4339e-05 - mae: 8.4240e-04 - val_loss: 3.7534e-08 - val_mae: 1.0964e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3.2428e-06 - mae: 4.4654e-04 - val_loss: 2.2144e-07 - val_mae: 2.6758e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.2208e-06 - mae: 7.0441e-04 - val_loss: 3.0545e-07 - val_mae: 3.5928e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 4.4786e-06 - mae: 8.9407e-04 - val_loss: 2.7260e-08 - val_mae: 8.5107e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.7231e-06 - mae: 6.0355e-04 - val_loss: 3.0223e-08 - val_mae: 1.2633e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.5433e-06 - mae: 6.4711e-04 - val_loss: 9.3013e-08 - val_mae: 2.5257e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.0356e-07 - mae: 3.0751e-04 - val_loss: 1.7767e-07 - val_mae: 3.5676e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 4.4369e-06 - mae: 4.9451e-04 - val_loss: 1.5486e-08 - val_mae: 9.8895e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3.7852e-06 - mae: 4.3690e-04 - val_loss: 1.1294e-09 - val_mae: 1.3847e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.6011e-06 - mae: 5.2540e-04 - val_loss: 1.6476e-06 - val_mae: 7.6351e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.8790e-06 - mae: 5.7361e-04 - val_loss: 6.4968e-06 - val_mae: 0.0019\n",
      "Epoch 36/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 4.3505e-06 - mae: 7.6434e-04 - val_loss: 3.6715e-05 - val_mae: 0.0047\n",
      "Epoch 37/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.1867e-06 - mae: 3.0293e-04 - val_loss: 8.0396e-10 - val_mae: 1.3281e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 4.7327e-07 - mae: 1.6334e-04 - val_loss: 7.4932e-10 - val_mae: 1.4752e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 6.6555e-07 - mae: 2.6195e-04 - val_loss: 9.1576e-09 - val_mae: 6.5690e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.4111e-07 - mae: 1.4919e-04 - val_loss: 1.5738e-08 - val_mae: 9.7329e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 6.0011e-07 - mae: 3.0087e-04 - val_loss: 6.8110e-07 - val_mae: 6.0514e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 9.9704e-07 - mae: 2.3818e-04 - val_loss: 1.5309e-08 - val_mae: 9.1909e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.2463e-06 - mae: 4.7310e-04 - val_loss: 1.7090e-09 - val_mae: 1.3674e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.0935e-07 - mae: 4.7953e-05 - val_loss: 1.0542e-09 - val_mae: 1.3457e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3.6953e-07 - mae: 1.5145e-04 - val_loss: 2.5283e-07 - val_mae: 4.6430e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 6.3880e-07 - mae: 2.2323e-04 - val_loss: 4.9423e-08 - val_mae: 1.8408e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 6.8770e-07 - mae: 3.0091e-04 - val_loss: 3.9480e-07 - val_mae: 4.9059e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.8533e-06 - mae: 3.7565e-04 - val_loss: 1.0021e-09 - val_mae: 1.4188e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3.8151e-08 - mae: 2.5604e-05 - val_loss: 1.9722e-10 - val_mae: 4.0065e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3.9447e-07 - mae: 2.0647e-04 - val_loss: 5.9937e-10 - val_mae: 1.4288e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.4257e-07 - mae: 7.0362e-05 - val_loss: 3.9931e-09 - val_mae: 3.9666e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.9952e-07 - mae: 1.2323e-04 - val_loss: 4.8995e-05 - val_mae: 0.0051\n",
      "Epoch 53/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.4445e-06 - mae: 3.2641e-04 - val_loss: 8.0827e-11 - val_mae: 4.4009e-06\n",
      "Epoch 54/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 6.5047e-07 - mae: 2.1005e-04 - val_loss: 1.7691e-10 - val_mae: 5.5838e-06\n",
      "Epoch 55/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3.8822e-07 - mae: 1.6303e-04 - val_loss: 4.6908e-10 - val_mae: 1.4953e-05\n",
      "Epoch 56/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.0927e-06 - mae: 1.9446e-04 - val_loss: 1.7694e-08 - val_mae: 9.8444e-05\n",
      "Epoch 57/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.1703e-07 - mae: 9.0703e-05 - val_loss: 4.6022e-10 - val_mae: 1.3199e-05\n",
      "Epoch 58/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.5921e-06 - mae: 2.5741e-04 - val_loss: 6.0429e-11 - val_mae: 2.9433e-06\n",
      "Epoch 59/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.0167e-06 - mae: 1.9793e-04 - val_loss: 1.9010e-09 - val_mae: 3.5212e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.3479e-07 - mae: 1.6297e-04 - val_loss: 6.3176e-10 - val_mae: 8.4637e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.1672e-07 - mae: 5.1213e-05 - val_loss: 6.4487e-11 - val_mae: 4.9058e-06\n",
      "Epoch 62/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 4.5268e-07 - mae: 2.1521e-04 - val_loss: 4.0197e-10 - val_mae: 5.9122e-06\n",
      "Epoch 63/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.9056e-07 - mae: 1.1256e-04 - val_loss: 8.4387e-09 - val_mae: 7.6888e-05\n",
      "Epoch 64/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.1341e-07 - mae: 7.8814e-05 - val_loss: 8.8549e-09 - val_mae: 7.6424e-05\n",
      "Epoch 65/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 5.3874e-07 - mae: 2.0188e-04 - val_loss: 1.6891e-05 - val_mae: 0.0033\n",
      "Epoch 66/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.6154e-06 - mae: 2.8995e-04 - val_loss: 8.7294e-10 - val_mae: 2.0850e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.4168e-07 - mae: 1.0637e-04 - val_loss: 3.7833e-10 - val_mae: 1.5909e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3.4747e-07 - mae: 2.2329e-04 - val_loss: 4.6147e-08 - val_mae: 1.6473e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 4.7857e-08 - mae: 7.7726e-05 - val_loss: 1.8043e-08 - val_mae: 1.0100e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 4.4903e-07 - mae: 2.5515e-04 - val_loss: 1.3185e-09 - val_mae: 3.0946e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3.1441e-07 - mae: 1.6095e-04 - val_loss: 2.9142e-10 - val_mae: 1.0398e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.3853e-07 - mae: 1.4063e-04 - val_loss: 1.2991e-08 - val_mae: 9.0892e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.9325e-08 - mae: 4.9351e-05 - val_loss: 1.4999e-09 - val_mae: 2.7914e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.3098e-07 - mae: 9.1499e-05 - val_loss: 1.3669e-06 - val_mae: 9.7440e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3.4158e-07 - mae: 2.0447e-04 - val_loss: 7.6940e-10 - val_mae: 2.0667e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3.7316e-07 - mae: 1.7110e-04 - val_loss: 8.7813e-09 - val_mae: 8.3441e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3.0552e-07 - mae: 8.4259e-05 - val_loss: 3.6065e-10 - val_mae: 1.3600e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.6659e-07 - mae: 1.3365e-04 - val_loss: 4.2271e-10 - val_mae: 6.4181e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 5.4822e-08 - mae: 3.0229e-05 - val_loss: 5.3123e-11 - val_mae: 3.3686e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.3796e-07 - mae: 8.7310e-05 - val_loss: 2.1909e-08 - val_mae: 1.2030e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.7075e-07 - mae: 2.3179e-04 - val_loss: 4.0811e-11 - val_mae: 3.1933e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.0638e-06 - mae: 2.4462e-04 - val_loss: 3.8240e-11 - val_mae: 3.1450e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 5.9130e-07 - mae: 1.7843e-04 - val_loss: 1.5410e-10 - val_mae: 7.6140e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.3467e-08 - mae: 3.5638e-05 - val_loss: 1.0104e-09 - val_mae: 2.4887e-05\n",
      "Epoch 85/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 5.4397e-07 - mae: 1.9503e-04 - val_loss: 1.8424e-07 - val_mae: 3.2248e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 5.6992e-07 - mae: 2.3107e-04 - val_loss: 3.0776e-10 - val_mae: 1.3240e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.6761e-07 - mae: 1.0104e-04 - val_loss: 2.9755e-07 - val_mae: 4.3327e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.9905e-07 - mae: 2.6013e-04 - val_loss: 1.4693e-10 - val_mae: 5.8748e-06\n",
      "Epoch 89/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.4992e-07 - mae: 9.2208e-05 - val_loss: 1.9778e-10 - val_mae: 1.0954e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.8281e-07 - mae: 8.1619e-05 - val_loss: 1.4924e-09 - val_mae: 2.5326e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3.9806e-07 - mae: 2.6690e-04 - val_loss: 7.4482e-11 - val_mae: 3.8712e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3.1041e-07 - mae: 7.7967e-05 - val_loss: 7.6353e-10 - val_mae: 1.9769e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.6962e-07 - mae: 9.0482e-05 - val_loss: 3.1805e-07 - val_mae: 4.2129e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 5.2237e-07 - mae: 2.8945e-04 - val_loss: 5.0158e-10 - val_mae: 9.4383e-06\n",
      "Epoch 95/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 3.4187e-10 - mae: 6.3977e-06 - val_loss: 5.0455e-09 - val_mae: 5.6549e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 5.6744e-07 - mae: 3.0184e-04 - val_loss: 1.1530e-10 - val_mae: 3.5901e-06\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 1.2603e-07 - mae: 7.6160e-05 - val_loss: 3.6994e-09 - val_mae: 5.2116e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.5698e-07 - mae: 1.2025e-04 - val_loss: 1.5373e-10 - val_mae: 6.4531e-06\n",
      "Epoch 99/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 7.0209e-08 - mae: 4.4255e-05 - val_loss: 1.2564e-10 - val_mae: 8.4049e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m2237/2237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 2.5519e-07 - mae: 1.5202e-04 - val_loss: 2.4061e-08 - val_mae: 1.1241e-04\n"
     ]
    }
   ],
   "source": [
    "# Assuming X and y are your features and target variable\n",
    "# X = ... (your input features)\n",
    "# y = ... (your target variable)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer: let's assume your input data has 5 features (adjust input_dim as needed)\n",
    "model.add(Dense(units=64, input_dim=X_train.shape[1], activation='relu'))  # First hidden layer\n",
    "model.add(Dense(units=32, activation='relu'))  # Second hidden layer\n",
    "model.add(Dense(units=1, activation='linear'))  # Output layer (assuming regression)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "462eade3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1198/1198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - loss: 2.4441e-08 - mae: 1.1280e-04\n",
      "Test Loss: 2.4404103626807228e-08\n",
      "Test MAE: 0.00011283629282843322\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5f2f02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1198/1198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b67f7ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15935785],\n",
       "       [0.07914165],\n",
       "       [0.27184817],\n",
       "       ...,\n",
       "       [0.11123226],\n",
       "       [0.11785503],\n",
       "       [0.42547545]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becb210c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
